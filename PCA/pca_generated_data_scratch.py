# -*- coding: utf-8 -*-
"""4/7/2023.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qkN10ESwncy092DLNcdYxdTP3fl9b6Vo
"""

#importing necessary libraries required for performing PCA
import pandas as pd
import numpy as np
from sklearn.datasets import make_classification
import random

#Generating the dataset
m=100;
n=100;
dataset=[]
dataset=make_classification(n_samples=m,n_features=n,random_state=40)

dataset #priting the dataset

def PCa(dataset,n_comp):  #Implementing PCA from basic
  dataset=dataset-np.mean(dataset,axis=0)
  cov=np.cov(dataset.T)
  eig_val=np.linalg.eig(cov)[0]  #All eigen values
  eigen_vec=np.linalg.eig(cov)[1] #All eigen vectors
  idx=eig_val.argsort()[::-1]
  eig_val=eig_val[idx]
  eigen_vec=eigen_vec[:,idx]    #sorting the eigen vectors by using the eigen values  ascending order sort
  proj_mat=eigen_vec[:,:n_comp]   #selecting the n eigen vectors with highest n eigen values
  dataset=np.dot(dataset,proj_mat) #Taking the dot product with the dataset two reduce its dimensions
  return dataset       #Returning the new dataset after PCA is performed

reduced_data=PCa(dataset[0],2)  #Applying the PCA on the generated dataset

reduced_data=pd.DataFrame(reduced_data,columns=['PC1','PC2'])  #The final dataset converting it into a dataframe and naming the columns new names

reduced_data #displyaing the new dataset aafter aaplying the PCA

#applying PCA using sklearn library
from sklearn.decomposition import PCA #importing PCA model from sklearn library

pca = PCA(n_components=2) #Model
x=pca.fit(dataset[0])   #fitting the generated data
x1=pca.transform(dataset[0]) #new data after applying pca

reduced_sklearn=pd.DataFrame(x1,columns=['PC1','PC2']) #convereting it into a dataframe

reduced_sklearn #Tranformed data after applying PCA using sklearn.